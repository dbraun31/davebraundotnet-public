<!DOCTYPE html>
<html><head>
    <meta charset="utf-8"/>
    <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
    
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap-grid.min.css" rel="stylesheet">
    <link href="/images/fav/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
    <script src="/js/code-folding.js?v=1.0.10" defer></script>
    <link href="/images/fav/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
    <link href="/images/fav/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
    <link href="/images/fav/site.webmanifest" rel="manifest"/>
    <title>404 Page not found | David Braun</title>
    <link href="/css/styles.css?v=1" rel="stylesheet"/>
    <link href="/css/override.css?v=1" rel="stylesheet"/>
    
</head><body><header>
    <div class="logo h-card">
        <a class="u-url" href="/">
            <img alt="Site Logo" class="site-logo u-photo" src="/images/logo.png"/>
        </a>
    </div>
    <nav class="menu">
        <ul>
                <li>
                    <a href="/about/">About</a>
                </li>
                <li>
                    <a href="/#contact">Contact</a>
                </li>
                <li>
                    <a href="/#results">Projects</a>
                </li>
                <li>
                    <a href="/publications/">Publications</a>
                </li>
        </ul>
    </nav>
</header>

<main style="display: flex; flex-direction: column; align-items: center; justify-content: center; min-height: 60vh; text-align: center; padding: 20px;">
    <h1 style="font-size: 5em; font-weight: bold;">404</h1>
    <p style="font-size: 1.5em;">Oops! We can't seem to find the page you are looking for.</p>
    <p style="margin-top: 20px; font-size: 1.2em;">Here's a little map to help you get back on track:</p>
    <a href="/" style="padding: 10px 20px; background-color: #b37c56; color: white; text-decoration: none; border-radius: 5px; margin-top: 10px;">Take Me Home</a>
</main>
<footer>
    <div class="social-media">
        
     
        
    </div>
    <div class="logo h-card">
        <a class="u-url" href="/">
            <img alt="Site Logo" class="site-logo u-photo" src="/images/logo.png"/>
        </a>
        <p>¬© 2025
            David Braun</p>
    </div>
    <nav>
        <ul>
                <li>
                    <a href="/about/">About</a>
                </li>
                <li>
                    <a href="/#contact">Contact</a>
                </li>
                <li>
                    <a href="/#results">Projects</a>
                </li>
                <li>
                    <a href="/publications/">Publications</a>
                </li>
        </ul>
    </nav>
    <script>
    window.store = {
    
    
    "\/": {
        
        "title": "David Braun",
            "tags": [],
    "content": "", 
    "url": "\/"
        },
    
    
    "\/2025\/04\/24\/does-the-brain-cope-with-anxiety-by-numbing-out\/": {
        
        "title": "Does the brain cope with anxiety by numbing out?",
            "tags": [],
    "content": " üìÑ Read the Paper\nüñº View the Poster\nTL;DR I used EEG and unsupervised machine learning techniques to analyze how the brain processes internal signals (interoception) and its link to anxiety. I found that the brain is less sensitive to internal signals during high energy states, a pattern that was amplified during states of anxiety\u0026mdash;insights from this project are relevant to stress detection and human-centered design.\nKey Skills üßπ Data Wrangling ‚Äì Cleaned high-dimensional EEG \u0026amp; physiological data üìä Exploratory Data Analysis ‚Äì Examined relationships between physiological and behavioral measures ü§ñ Machine learning ‚Äì Applied signal separation for artifact removal and clustering to extract insights üìà Visualization ‚Äì Created clear, insight-driven plots What I Learned How to extract meaningful signals from noisy biological data, a skill transferable to real-world time-series analysis (wearables, health tech, user behavior modeling).\nSometimes life is angsty. We\u0026rsquo;ve all been there\u0026mdash;you\u0026rsquo;re about to talk in front of a group, have a difficult conversation with someone, or do some task where a mistake would be really bad. While it might be healthier not to avoid anxiety, sometimes it\u0026rsquo;s just easier to reach for a distraction. What you may not know is that your brain might subconsciously be trying to avoid anxiety as well.\nFigure 1: Distraction is an easy way to avoid feeling anxiety.\n## [1] \u0026#34;/home/dave/Dropbox/post_doc/professional/career/davebraundotnet/blogdown/content/post/hep\u0026#34; What we were interested in We wanted to look at how the brain responds to heartbeats across different states of anxiety and energy Previous research suggests that anxiety disrupts our brain\u0026rsquo;s subconsious sensitivity to bodily signals, a sensitivity referred to as interoception. 1 Interoception is our brain\u0026rsquo;s way of sensing and regulating many of the body\u0026rsquo;s functions, such as breathing and responding to heart rhythms.\nDifferences in interoception have also been linked to differences in one\u0026rsquo;s sense of energy or activation2,3\u0026mdash;a sense we\u0026rsquo;ll refer to as subjective arousal. Subjective arousal\u0026mdash;much like anxiety and interoception\u0026mdash;is continually and spontaneously fluctuating, even when people are just at rest. But no previous study has looked at how subjective arousal, anxiety, and interoception spontaneously fluctuate with each other at rest.\nWe wanted to look at how the brain responds to bodily signals\u0026mdash;specifically, heartbeats\u0026mdash;during spontaneous fluctuations in subjective arousal when people are at rest, and how this interaction might be different for those low vs. high in anxiety. How these processes play out at rest might be important because certain brain networks are typically only active at rest, and these networks contribute to patterns like rumination and worry that feed into anxiety. 4\nUnderstanding how the brain shifts interoception in response to changing subjective arousal states during rest might help us better understand processes that underlie anxiety.\nHow we did it We measured electrical activity from the brain and heart during rest and occassionally asked people how they were feeling A precise way to measure neural interoception is through what\u0026rsquo;s called the heartbeat evoked potential (HEP), which is basically the brain\u0026rsquo;s electrophysiological response to heartbeats.5 Your brain is constantly emitting electricity (emanating from the communication between neurons), and when the brain\u0026rsquo;s electrical response is high following a heartbeat, that\u0026rsquo;s thought to reflect higher levels of neural interoceptive sensitivity to the heart.\nParticipants (51) came into our lab and completed a survey indicating their level of state anxiety, or how much anxiety they were experiencing in that moment. We then fitted them with an EEG cap to measure their neural electrical signals. This EEG cap included 31 scalp electrodes plus an electrode that we placed on participants\u0026rsquo; back (ECG) to measure their heartbeat activity (see Figure 2).\nFigure 2: (A) Cartoonized illustration of EEG cap and (B) placement of EEG electrodes in the experiment according to the 10-20 coordinate system\nParticipants stared at a blank screen and were told to let their minds wander freely. Every so often, a set of questions (ie, a thought probe) appeared asking participants to report different aspects of their experience. Most important was the question asking about their level of subjective arousal, which includes feelings of energy linked to emotion, and participants gave ratings on a scale from 0 (completely deactivated) to 100 (completely activated; see Figure 3A).\nFigure 3: Trial sequence and analysis approach. (A) Participants were instructed to let their minds wander freely while viewing a blank screen and occasionally reported on aspects of their experience (such as their level of subjective arousal). (B) Brain EEG signals before a thought probe and directly after heartbeats were averaged together, separated by a median split in subjective arousal, and submitted to a whole-brain analysis (ie, cluster-based permutation analysis).\nTo calculate the HEP, I isolated the 10 s period before the onset of a thought probe and extracted the EEG signals (from all 31 electrodes) that occurred directly after a heartbeat (see Figure 3B). I then separated the 10 s pre-probe periods according to whether the subjective arousal rating obtained during the thought probe was high or low (based on a within-participants median split on subjective arousal).\nFinally, I averaged across the high vs. low levels of subjective arousal (collapsing across heartbeats and probes), which gave me one averaged brain signal value for timepoints immediately following a heartbeat, for each EEG channel, for each subjective arousal condition, across all participants. In other words, we had for each participant an array of shape (timepoints x channel x condition), or (100 x 31 x 2).\nUltimately, we wanted to know how interoceptive sensitivity to cardiac signals (as measured with HEPs) is different in periods leading up to self-reported high vs. low states of subjective arousal. To assess this, I took those arrays defined in the previous paragraph and conducted a whole brain analysis using what\u0026rsquo;s called a cluster-based permutation test.\nCluster-based permutation test is a super powerful and flexible data-driven method for finding differences between conditions in high-dimensional space. In our example, the conditions are a median split on subjective arousal ratings, each thought probe was labelled as \u0026ldquo;high\u0026rdquo; or \u0026ldquo;low\u0026rdquo; subjective arousal. The high dimensional space is the remaining (time x channels) array of EEG data for each participant. In short, we want to find whether EEG voltage is different across high vs. low levels of subjective arousal conditions at any timepoint(s) and for any EEG channel(s).\nExpand this section to optionally read more about cluster-based permutation test and see how I implemented it with code. Technical spotlight: Cluster-based permutation testing What is a cluster-based permutation test? We\u0026rsquo;re trying to find a meaningful pattern in brain data, but brain data is massive. In our case, we\u0026rsquo;re looking across 6,200 data points. If we tested each one individually, we\u0026rsquo;d almost certainly get false positives (random noise that looks meaningful).\nA cluster-based permutation test helps solve this.\nThe core idea:\nInstead of asking \u0026ldquo;is this single time point significant?\u0026rdquo;, we ask:\nAre there clusters of nearby data points that are all showing an effect?\nIf a real difference exists, we expect it to show up not just as a blip, but as a spatially or temporally coherent cluster.\nHow it works:\nCompute the actual data difference between two groups (eg, high vs. low subjective arousal) at every point in time or space. Identify clusters of adjacent points that pass some basic threshold (eg, t-values \u0026gt; 2). Calculate a cluster-level statistic (like the sum of t-values) for each cluster. Randomly shuffle the group labels many times (eg, 5,000 permutations) and repeat steps 1-3 each time. Compare your original clusters to the shuffled ones. If a real cluster is bigger than 95% of the ones you\u0026rsquo;d see by chance, it\u0026rsquo;s considered statistically significant. What makes this approch so powerful is that it doesn\u0026rsquo;t rely on strict assumptions about what the data would look like if there were no effect (ie, a null distribution). Instead, it builds a null distribution directly from the data. This allows us to compare many data points over an arbitrary number of dimensions to look for significant effects, making cluster-based permutation testing the perfect tool for finding differences in our brain data.\nHow I implemented it To make the cluster-based permutation test flexible and reproducible, I wrote a collection of functions in both Python and R and coordinated them with R\u0026rsquo;s fancy reticulate package. The Python functions actually ran the cluster test using mne.stats.spatio_temporal_cluster_test, and the R functions were mostly for summarizing the result. I\u0026rsquo;m highlighting here the main Python function doing most of the work, but you can see the full set of functions on GitHub (for Python and R).\nThe whole main Python function:\nfrom pathlib import Path import pickle from mne.stats import spatio_temporal_cluster_test def permutation_cluster_test(item, low_anchor, bads, time_window_min=0.25, initial_alpha=0.01, path=Path(\u0026#39;analysis/data/derivatives/hep/06-evoked-clean\u0026#39;)): \u0026#39;\u0026#39;\u0026#39; Conducts a permutation-based clustering analysis across a median split of item, analyzing time points from time_window_min to end of epoch. --- PARAMETERS --- ------------------ item (str): Item name low_anchor (str): Name of low anchor on the scale (all lowercase) time_window_min (float): Analyze time points after this value initial_alpha (float): Alpha for finding initial clusters path (pathlib.Path): Path to directory containing data --- RETURNS --- --------------- out (dict) containing results of permutation test: t_obs: (N_timepoints x M_channels) matrix with t values as elements clusters: list of (array(time_idx, ...), array(channel_idx, ...)) tuples of all found clusters p_values: np.array of shape (N_clusters,) where each element is a p value \u0026#39;\u0026#39;\u0026#39; # Open dictionary assert(isinstance(item, str)) file = \u0026#39;eeg_dict_{}.pkl\u0026#39;.format(item) full_path = path / Path(file) with open(full_path, \u0026#39;rb\u0026#39;) as f: dic = pickle.load(f) # Ensure bads is a list of ints if isinstance(bads, list): bads = [int(x) for x in bads] else: bads = [int(bads)] # Get numpy arrays of shape (subjects, time, chans) for each condition low, high = _format_for_clustering(dic, low_anchor, bads) # Get a sample evoked object for computing distances probe_set = dic[list(dic.keys())[0]][low_anchor] sample_evoked = probe_set[list(probe_set.keys())[0]] adjacency, _ = find_ch_adjacency(sample_evoked.info, \u0026#39;eeg\u0026#39;) # Get the first index of timepoint thats \u0026gt;= the min timepoint time_window_idx = [i for i, e in enumerate(sample_evoked.times) if e \u0026gt;= time_window_min][0] times = sample_evoked.times[time_window_idx:] channels = sample_evoked.info[\u0026#39;ch_names\u0026#39;] # Format data as list of arrays X = [low[:, time_window_idx:, :], high[:, time_window_idx:, :]] # Configure parameters df = low.shape[0] - 1 t_crit = stats.t.ppf(1 - initial_alpha, df) tail = 0 # Run test t_obs, clusters, p_values, _ = spatio_temporal_cluster_test( X, n_permutations=1000, threshold=t_crit, tail=tail, n_jobs=None, seed = 1510, buffer_size=None, adjacency=adjacency, stat_fun=_my_t ) out = {\u0026#39;t_obs\u0026#39;: t_obs, \u0026#39;clusters\u0026#39;: clusters, \u0026#39;p_values\u0026#39;: p_values, \u0026#39;times\u0026#39;: times, \u0026#39;channels\u0026#39;: channels} return out Let\u0026rsquo;s zoom into the important stuff.\nThe actual cluster-based permutation test is being run with this code:\n# Run test t_obs, clusters, p_values, _ = spatio_temporal_cluster_test( X, n_permutations=1000, threshold=t_crit, tail=tail, n_jobs=None, seed = 1510, buffer_size=None, adjacency=adjacency, stat_fun=_my_t ) This function (spatio_temporal_cluster_test) comes from the MNE library, which is an excellent set of EEG/MEG analysis tools written for Python. Let\u0026rsquo;s step through the important input arguments.\nThe input data\nThe input data (X) needs to be formatted as a list of arrays, where each array in the list is data from one of the conditions\u0026mdash;in our case, the two subjective arousal conditions (high vs. low). This formatting is done by the following lines of code:\n# Get numpy arrays of shape (subjects, time, chans) for each condition low, high = _format_for_clustering(dic, low_anchor, bads) # Format data as list of arrays X = [low[:, time_window_idx:, :], high[:, time_window_idx:, :]] I\u0026rsquo;m first calling one of my other functions (not shown above) to format the relevant data into two arrays split by subjective arousal condition. These arrays represent the data across each timepoint and channel for each subject. Next, I\u0026rsquo;m concatenating these two arrays into a list\u0026mdash;taking only a subset of the time window with time_window_idx\u0026mdash;which serves as our final input data X. We\u0026rsquo;re analyzing only a subset of the time window because we want to conduct our statistics only on those measurements that occur at least 250 ms after each heartbeat, which is to ensure that heartbeat activity doesn\u0026rsquo;t contaminate the neural activity we\u0026rsquo;re interested in analyzing.\nThe statistical hyperparameters\nWe need to configure a number of statistical hyperparameters that will influence how the cluster test algorithm runs. We first need to decide on what is a significant threshold for forming a cluster in the first place (ie, the threshold input argument). Since we\u0026rsquo;re only comparing two conditions within participants, the statistical test we use to compute this threshold is a paired-samples t test (which is defined in the _my_t function and passed to the stat_fun input argument of the cluster analysis).\nFor each of the many, many comparisons across data points, the algorithm computes one t test, and the threshold we set determines whether the resulting t value is considered significant. Significant t values that are adjacent to one another in data space are considered to be a \u0026ldquo;cluster\u0026rdquo;. For this type of test, it\u0026rsquo;s common to use an alpha value (ie, false positive rate) of 0.01 as a cluster forming threshold. But we need to convert that alpha to a t value, and for that we use the quantile function of the t distribution (ie, the function that maps probability values to t values, or the inverse cumulative distribution function):\n# Configure parameters df = low.shape[0] - 1 t_crit = stats.t.ppf(1 - initial_alpha, df) tail = 0 The degrees of freedom (df) is the number of participants minus 1, and we subtract alpha from 1 to calculate the cumulative density between the tail of the t distribution and the alpha value. Finally, tail=0 tells the algorithm we want to perform a two-tailed test, meaning either condition can have greater EEG voltage than the other.\nThe algorithm returns the data points of all the clusters found, along with the t values across all data points, and cluster-specific p values. If a cluster has a cluster-level p value of less than .05, we know there was a significant difference across subjective arousal conditions during the cluster\u0026rsquo;s time period and for that cluster\u0026rsquo;s channels. Below (Figure 4) is a heat map of the t values across all data points (with a preview of a signifcant cluster):\n# Read in data m \u0026lt;- readRDS(\u0026#39;post_data/cluster_result.rds\u0026#39;) # Parse time and channels, make data frame channels \u0026lt;- colnames(m$eeg)[which(colnames(m$eeg)==\u0026#39;Fp1\u0026#39;):ncol(m$eeg)] times \u0026lt;- unique(m$eeg$time) times \u0026lt;- times[times \u0026gt;= .25] ts \u0026lt;- as.data.frame(m$result$t_obs) colnames(ts) \u0026lt;- channels ts \u0026lt;- cbind(data.frame(time = times, ts)) # Configure colors and plot blues \u0026lt;- brewer.pal(5, \u0026#39;Blues\u0026#39;) blues_g \u0026lt;- colorRampPalette(c(blues[1], blues[5]))(100) ts %\u0026gt;% gather(channel, t, Fp1:POz) %\u0026gt;% mutate(channel = factor(channel, levels = rev(channels))) %\u0026gt;% ggplot(aes(x = time, y = channel)) + geom_tile(aes(fill = t)) + geom_rect(aes(ymin = \u0026#39;C3\u0026#39;, ymax = 31.5, xmin = .31, xmax = .38), fill = NA, color = \u0026#39;green\u0026#39;, linetype = \u0026#39;dashed\u0026#39;, linewidth = 1.5) + scale_fill_gradientn(colors = blues_g) + labs( x = \u0026#39;Time post heartbeat (s)\u0026#39;, y = \u0026#39;EEG Channels\u0026#39;, fill = \u0026#39;t value\u0026#39; ) + theme_bw() + theme(panel.grid = element_blank(), axis.ticks = element_blank()) Figure 4: Heat map of t values from cluster-based permutation analysis across time and EEG channels. Time is relative to heartbeat onset. First letter of channel suggests it's position on the scalp (ie, F=frontal, C=central, T=temporal, P=parietal, O=occipital). Darker blues indicate higher t values, revealing a larger difference in the EEG signal between subjective arousal conditions. Green dashed lines highlight the significant cluster.\nThat\u0026rsquo;s it for the technical spotlight! Now back to the main post.\nResearch questions In this post, I address three questions with the analyses:\nHow was our measure of subjective arousal related to physiological arousal? How does interoception (as measured with HEP) vary across states of subjective arousal? How does the relationship between interoception and subjective arousal change depending on state anxiety? What we found 1. Subjective arousal was unrelated to physiological arousal and somewhat related to other dimensions of experience To first get a better sense of what we were really measuring with our subjective arousal scale, I looked at how subjective arousal ratings compared to (i) more traditional measures of objective, physiological arousal (such as heartrate), and (ii) how subjective arousal related to other dimensions of ongoing experience that we measured with our thought probes (such as tendency to think about the future). Figure 5 shows participant-specific correlations between subjective arousal and both heartrate and future thinking.\n# Import data d \u0026lt;- read.csv(\u0026#39;post_data/MW_EEG_behavioral.csv\u0026#39;) bads \u0026lt;- c(10, 13, 14) d \u0026lt;- d[!d$subject %in% bads,] ecg \u0026lt;- read.csv(\u0026#39;post_data/MW_ECG_summary.csv\u0026#39;) # Mean imputation on very few missing values d \u0026lt;- d %\u0026gt;% group_by(subject) %\u0026gt;% # Mean imputation mutate(trial = 1:(n()), arou = ifelse(!is.na(arou), arou, mean(arou, na.rm=TRUE))) %\u0026gt;% ungroup() %\u0026gt;% select(subject, trial, arou, fut) # Summarize heart metric heart \u0026lt;- ecg %\u0026gt;% rename(trial = probe) %\u0026gt;% mutate(trial = as.integer(gsub(\u0026#39;Probe\u0026#39;, \u0026#39;\u0026#39;, trial)), timepoint = sample / 250) %\u0026gt;% mutate(hr = 60 / (timepoint - lag(timepoint))) %\u0026gt;% group_by(subject, trial) %\u0026gt;% summarize(hr = mean(hr, na.rm=TRUE)) %\u0026gt;% inner_join(d) ## `summarise()` has grouped output by \u0026#39;subject\u0026#39;. You can override using the ## `.groups` argument. ## Joining with `by = join_by(subject, trial)` # Compute summaries for viz sd \u0026lt;- heart %\u0026gt;% gather(metric, measure, hr, fut) %\u0026gt;% group_by(subject, metric) %\u0026gt;% summarize(r = cor.test(measure, arou)$estimate, ci_l = cor.test(measure, arou)$conf.int[1], ci_h = cor.test(measure, arou)$conf.int[2], p = cor.test(measure, arou)$p.value) %\u0026gt;% mutate(sig = case_when( p \u0026lt; .001 ~ \u0026#39;p \u0026lt; .001\u0026#39;, p \u0026lt; .01 ~ \u0026#39;p \u0026lt; .01\u0026#39;, p \u0026lt; .05 ~ \u0026#39;p \u0026lt; .05\u0026#39;, p \u0026gt;= .05 ~ \u0026#39;N.S.\u0026#39; )) %\u0026gt;% mutate(sig = factor(sig, levels = c(\u0026#39;N.S.\u0026#39;, \u0026#39;p \u0026lt; .05\u0026#39;, \u0026#39;p \u0026lt; .01\u0026#39;, \u0026#39;p \u0026lt; .001\u0026#39;))) ## `summarise()` has grouped output by \u0026#39;subject\u0026#39;. You can override using the ## `.groups` argument. # --- COMPUTE AGGREGATE STATS --- # # Use Fisher Z to transform correlations to unbounded space fisherz \u0026lt;- function(r) { return(0.5 * log((1 + r) / (1 - r))) } sd$z \u0026lt;- fisherz(sd$r) N \u0026lt;- length(unique(sd$subject)) # Aggregate correlation statistics stats \u0026lt;- sd %\u0026gt;% group_by(metric) %\u0026gt;% summarize(m = mean(r), se = sd(r) / sqrt(N), t = t.test(r, mu=0)$statistic, df = t.test(r, mu=0)$parameter, p = t.test(r, mu=0)$p.value, bf = (extractBF(ttestBF(r, mu=0))$bf)) %\u0026gt;% mutate(p_code = ifelse(p \u0026lt; .001, \u0026#39;\u0026lt; .001\u0026#39;, paste0(\u0026#39;= \u0026#39;, round(p, 3))), bf = ifelse(metric==\u0026#39;fut\u0026#39;, bf, 1 / bf)) %\u0026gt;% mutate(r = -1, subject = c(1, 24), label = paste0(\u0026#39;p \u0026#39;, p_code, c(\u0026#39;\\nBF Alt = \u0026#39;, \u0026#39;\\nBF Null = \u0026#39;), round(bf, 2))) metric_order \u0026lt;- c(\u0026#39;hr\u0026#39;, \u0026#39;fut\u0026#39;) stats$metric \u0026lt;- factor(stats$metric, levels = metric_order) stats$metric \u0026lt;- recode(stats$metric, `hr` = \u0026#39;Heart rate\u0026#39;, `fut` = \u0026#39;Future thinking\u0026#39;) colors \u0026lt;- brewer_pal(palette = \u0026#39;RdBu\u0026#39;)(10)[c(1, 10, 8, 6)] # Visualize p3 \u0026lt;- sd %\u0026gt;% mutate(metric = factor(metric, levels = metric_order)) %\u0026gt;% mutate(metric = recode(metric, `hr` = \u0026#39;Heart rate\u0026#39;, `fut` = \u0026#39;Future thinking\u0026#39;)) %\u0026gt;% ggplot(aes(x = reorder_within(subject, r, metric), y = r)) + geom_hline(yintercept = 0, linetype = \u0026#39;dashed\u0026#39;) + geom_errorbar(aes(ymin = ci_l, ymax = ci_h, color = sig), width = .2, linewidth = .5) + geom_point(aes(color = sig), size = .5) + geom_text(data = stats, aes(label=label), size = 3, hjust = 0) + scale_color_manual(values = colors) + labs( x = \u0026#39;Participant\u0026#39;, y = \u0026#39;Within-participant correlation with subjective arousal\u0026#39;, color = \u0026#39;\u0026#39; ) + scale_x_reordered() + scale_y_continuous(breaks = c(-1, 0, 1), labels = c(-1, 0, 1), limits = c(-1, 1)) + coord_flip() + facet_wrap(~metric, scales = \u0026#39;free\u0026#39;, ncol = 3) + theme_bw() + theme(axis.ticks = element_blank(), axis.text.y = element_blank(), strip.background = element_rect(fill = NA), panel.grid = element_blank(), legend.position = c(.39, .3), legend.key.size = unit(.2, \u0026#39;cm\u0026#39;), legend.text = element_text(size = 8), legend.spacing.y = unit(0, \u0026#39;pt\u0026#39;), legend.title = element_blank(), text = element_text(size = 14)) p3 Figure 5: Participant-level correlations between subjective arousal, tendency to think about the future, and heartrate. Bayes factors and p values characterize a one-sample t test against zero.\nWe can see that, for just about all participants, ratings of subjective arousal are largely unrelated to their average heart rate. We can also see that, for many participants, thinking about the future was associated with higher subjective arousal ratings. This makes sense if thinking about the future is energizing or stressful.\n2. Interoceptive sensitivity to cardiac signals is stronger during states of lower subjective arousal To assess whether interoception to cardiac signals changes based on subjective arousal, we examined the results of the cluster-based permutation test, and found one significant cluster. This cluster occurred largely over frontal electrodes about 350 ms post heartbeat.\nlibrary(ggpubr) source(\u0026#39;visualize_clusters.r\u0026#39;) ## ## Attaching package: \u0026#39;arrow\u0026#39; ## The following object is masked from \u0026#39;package:lubridate\u0026#39;: ## ## duration ## The following object is masked from \u0026#39;package:utils\u0026#39;: ## ## timestamp ## ## Attaching package: \u0026#39;eegUtils\u0026#39; ## The following object is masked from \u0026#39;package:stats\u0026#39;: ## ## filter ## here() starts at /home/dave/Dropbox/post_doc/professional/career/davebraundotnet/blogdown m \u0026lt;- readRDS(\u0026#39;post_data/cluster_result.rds\u0026#39;) cluster_id \u0026lt;- which(m$result$p_values \u0026lt; .05) topo \u0026lt;- plot_topo(m, cluster_id, n_breaks = 1, nrow = 1) ## Joining with `by = join_by(channel)` ## Warning in geom_topo(chan_markers = \u0026#34;text\u0026#34;, aes(fill = t_statistic, label = ## electrode)): Ignoring unknown aesthetics: label ## Warning in geom_topo(chan_markers = \u0026#34;text\u0026#34;, aes(fill = t_statistic, label = electrode)): Ignoring unknown aesthetics: fill and label ## Ignoring unknown aesthetics: fill and label ## Ignoring unknown aesthetics: fill and label ## Warning in geom_topo(chan_markers = \u0026#34;text\u0026#34;, aes(fill = t_statistic, label = ## electrode)): Ignoring unknown aesthetics: fill ## Warning in geom_topo(chan_markers = \u0026#34;text\u0026#34;, aes(fill = t_statistic, label = ## electrode)): Ignoring unknown aesthetics: fill and label channels \u0026lt;- m$result$channels[m$result$clusters[[2]][[2]] + 1] times \u0026lt;- m$result$times[m$result$clusters[[2]][[1]] + 1] d \u0026lt;- m$eeg N \u0026lt;- length(unique(d$subject)) pd \u0026lt;- d %\u0026gt;% gather(channel, voltage, Fp1:POz) %\u0026gt;% filter(channel %in% channels) %\u0026gt;% group_by(subject, condition, time) %\u0026gt;% summarize(voltage_ = mean(voltage)) %\u0026gt;% group_by(condition, time) %\u0026gt;% summarize(voltage = mean(voltage_), se = sd(voltage_) / sqrt(N)) ## `summarise()` has grouped output by \u0026#39;subject\u0026#39;, \u0026#39;condition\u0026#39;. You can override ## using the `.groups` argument. ## `summarise()` has grouped output by \u0026#39;condition\u0026#39;. You can override using the ## `.groups` argument. rib \u0026lt;- pd %\u0026gt;% filter(time %in% times) %\u0026gt;% group_by(time) %\u0026gt;% summarize(ymin = min(voltage, na.rm = TRUE), ymax = max(voltage, na.rm = TRUE)) low \u0026lt;- \u0026#39;#FC8D59\u0026#39; high \u0026lt;- \u0026#39;#91BFDB\u0026#39; ts \u0026lt;- pd %\u0026gt;% ggplot(aes(x = time, y = voltage)) + geom_rect(aes(xmin = .25, xmax = .650, ymin = min(voltage), ymax = max(voltage)), color = \u0026#39;steelblue\u0026#39;, fill = NA, linetype = \u0026#39;dashed\u0026#39;) + geom_ribbon(data = rib, aes(ymin = ymin, ymax = ymax, xmin = times[1], xmax = times[length(times)], y=1), alpha = .6, fill = \u0026#39;green\u0026#39;) + geom_ribbon(aes(ymin = voltage - se, ymax = voltage + se, fill = condition), alpha = .3) + geom_line(aes(color = condition)) + labs( title = \u0026#39;Heartbeat evoked potential (HEP)\u0026#39;, x = \u0026#39;Time post heartbeat (s)\u0026#39;, y = latex2exp::TeX(\u0026#39;$EEG Voltage~ (\\\\mu ~V)$\u0026#39;), color = \u0026#39;Subjective arousal\u0026#39;, fill = \u0026#39;Subjective arousal\u0026#39; ) + scale_color_manual(values = c(Deactivated = low, Activated = high)) + scale_fill_manual(values = c(Deactivated = low, Activated = high)) + theme_bw() + theme(axis.ticks = element_blank(), panel.grid = element_blank(), legend.position = \u0026#39;bottom\u0026#39;) g \u0026lt;- ggarrange(ts, topo, labels = c(\u0026#39;A.\u0026#39;, \u0026#39;B.\u0026#39;), nrow=2) print(g) Figure 6: Main result of cluster-based permutation analysis. (A) The grand averaged timeseries of EEG voltage timelocked to the heartbeat (ie, the HEP). Blue dashed rectangle highlights the time points that were analyzed in the cluster test. Green shaded area highlights the significant cluster. (B) Topographical heat map of t values during the significant time window (at time point 0.328 s post heartbeat). The significant cluster centers on frontal electrodes.\nFigure 6 highlights the significant cluster from the cluster-based permutation analysis. We can see that, on average, EEG voltage was higher (ie, stronger interoception) prior to lower ratings of subjective arousal. This suggests that participants were more sensitive to cardiac signals during periods of lower subjective arousal.\n3. The link between interoceptive sensitivity and subjective arousal was amplified for those high in state anxiety Given the strong links between anxiety and interoception1, we next wanted to look at how this HEP effect we found might be different for those with low vs. high anxiety. At the beginning of the experiment, we collected measures of both trait anxiety (ie, how much anxiety one experiences generally) and state anxiety (ie, how much anxiety one is experience while completing the survey).\nIf I were to plot that significant green window in Figure @ref(fig:cluster_result) for each participant, we would see that each participant is different with respect to how strong their link is between interoception and subjective arousal (ie, their HEP effect). We wanted to know whether these differences could be explained by differences in state or trait anxiety.\nSo, for each participant, I calculated their average HEP effect and correlated it with their anxiety measures:\n# --- TOP PANEL --- # # Individual-level correlations between HEP effect size and survey response # Select correct data channels_s \u0026lt;- m$result$channels[m$result$clusters[[2]][[2]] + 1] times_s \u0026lt;- m$result$times[m$result$clusters[[2]][[1]] + 1] cluster \u0026lt;- data.frame(time = times_s, channel = channels_s) cluster$string \u0026lt;- paste(cluster$time, cluster$channel, sep=\u0026#39;_\u0026#39;) survey \u0026lt;- read.csv(\u0026#39;post_data/MW_EEG_survey.csv\u0026#39;) survey \u0026lt;- survey[, c(\u0026#39;subj_id\u0026#39;, \u0026#39;GAD7_Score\u0026#39;, \u0026#39;STAI_Score\u0026#39;)] colnames(survey) \u0026lt;- c(\u0026#39;subject\u0026#39;, \u0026#39;gad\u0026#39;, \u0026#39;stai\u0026#39;) d \u0026lt;- m$eeg # Select appropriate (significant) cluster hep_s \u0026lt;- d %\u0026gt;% gather(channel, voltage, Fp1:POz) %\u0026gt;% mutate(string = paste(time, channel, sep=\u0026#39;_\u0026#39;)) %\u0026gt;% filter(string %in% cluster$string, channel %in% channels_s) %\u0026gt;% group_by(subject, condition) %\u0026gt;% summarize(voltage = mean(voltage)) %\u0026gt;% mutate(condition = ifelse(condition == \u0026#39;Activated\u0026#39;, \u0026#39;High Arousal\u0026#39;, \u0026#39;Low Arousal\u0026#39;)) %\u0026gt;% inner_join(survey) ## `summarise()` has grouped output by \u0026#39;subject\u0026#39;. You can override using the ## `.groups` argument. ## Joining with `by = join_by(subject)` # Make general summarized data t \u0026lt;- hep_s %\u0026gt;% spread(condition, voltage) %\u0026gt;% mutate(hep = `Low Arousal` - `High Arousal`) %\u0026gt;% select(-`High Arousal`, -`Low Arousal`) %\u0026gt;% gather(survey, response, gad,stai) %\u0026gt;% mutate(survey = recode(survey, `gad` = \u0026#39;Trait anxiety\u0026#39;, `stai` = \u0026#39;State anxiety\u0026#39;)) # Compute group-level correlations cr \u0026lt;- t %\u0026gt;% group_by(survey) %\u0026gt;% summarize(r = cor.test(hep, response)$estimate, df = cor.test(hep, response)$parameter, p = cor.test(hep, response)$p.value, ci_h = cor.test(hep, response)$conf.int[1], ci_l = cor.test(hep, response)$conf.int[2]) %\u0026gt;% mutate(label = paste0(\u0026#39;r(\u0026#39;, df, \u0026#39;) = \u0026#39;, round(r, 3), \u0026#39;\\n95% CI = [\u0026#39;, round(ci_l, 3), \u0026#39;, \u0026#39;, round(ci_h, 3), \u0026#39;]\\np = \u0026#39;, round(p, 3)), hep = c(-.5, -.5), response = c(39, 10), survey = c(\u0026#39;State anxiety\u0026#39;, \u0026#39;Trait anxiety\u0026#39;)) # Visualize correlations p1 \u0026lt;- t %\u0026gt;% filter(!is.na(response)) %\u0026gt;% ggplot(aes(x = response, hep)) + geom_point() + geom_smooth(method = \u0026#39;lm\u0026#39;) + facet_wrap(~survey, scales = \u0026#39;free_x\u0026#39;) + geom_text(data = cr, aes(label = label), hjust = 0, size = 3) + labs( x = \u0026#39;Survey response\u0026#39;, y = \u0026#39;Participant-specific\\nHEP effect size\u0026#39; ) + ylim(-1, 1) + theme_bw() + theme(panel.grid = element_blank(), strip.background = element_rect(fill = NA, color = \u0026#39;black\u0026#39;), axis.ticks = element_blank()) # --- PANEL 2 --- # # Visualize median split on EEG timeseries # Keep relevant columns channels_s \u0026lt;- unique(channels_s) d \u0026lt;- m$eeg mask1 \u0026lt;- colnames(d) %in% c(\u0026#39;subject\u0026#39;, \u0026#39;condition\u0026#39;, \u0026#39;time\u0026#39;) mask2 \u0026lt;- colnames(d) %in% channels_s d \u0026lt;- d[, (mask1 | mask2)] # Plot p2 \u0026lt;- d %\u0026gt;% inner_join(survey[,c(\u0026#39;subject\u0026#39;, \u0026#39;stai\u0026#39;)]) %\u0026gt;% filter(!is.na(stai), time %in% times) %\u0026gt;% mutate(stai_d = ifelse(stai \u0026gt; median(stai), \u0026#39;High state anxiety\u0026#39;, \u0026#39;Low state anxiety\u0026#39;)) %\u0026gt;% gather(channel, voltage, Fp1:FC5) %\u0026gt;% group_by(subject, time, condition, stai_d) %\u0026gt;% summarize(voltage_ = mean(voltage)) %\u0026gt;% group_by(time, condition, stai_d) %\u0026gt;% summarize(voltage = mean(voltage_), se = sd(voltage_) / sqrt(n())) %\u0026gt;% mutate(stai_d = factor(stai_d, levels = c(\u0026#39;Low state anxiety\u0026#39;, \u0026#39;High state anxiety\u0026#39;))) %\u0026gt;% ggplot(aes(x = time, y = voltage)) + geom_ribbon(aes(ymin = voltage - se, ymax = voltage + se, fill = condition), alpha = .3) + geom_line(aes(color = condition)) + facet_wrap(~stai_d) + labs( x = \u0026#39;Time post heartbeat (s)\u0026#39;, y = latex2exp::TeX(\u0026#39;$EEG~voltage~(\\\\mu ~V)$\u0026#39;), fill = \u0026#39;Subjective arousal\u0026#39;, color = \u0026#39;Subjective arousal\u0026#39; ) + scale_color_manual(values = c(`Activated` = high, `Deactivated` = low)) + scale_fill_manual(values = c(`Activated` = high, `Deactivated` = low)) + theme_bw() + theme(panel.grid = element_blank(), strip.background = element_rect(fill = NA, color = \u0026#39;black\u0026#39;), axis.ticks = element_blank(), legend.position = \u0026#39;bottom\u0026#39;) ## Joining with `by = join_by(subject)` ## `summarise()` has grouped output by \u0026#39;subject\u0026#39;, \u0026#39;time\u0026#39;, \u0026#39;condition\u0026#39;. You can ## override using the `.groups` argument. ## `summarise()` has grouped output by \u0026#39;time\u0026#39;, \u0026#39;condition\u0026#39;. You can override using ## the `.groups` argument. g \u0026lt;- ggarrange(p1, p2, labels = c(\u0026#39;A.\u0026#39;, \u0026#39;B.\u0026#39;), nrow = 2) ## `geom_smooth()` using formula = \u0026#39;y ~ x\u0026#39; ## Warning: Removed 2 rows containing non-finite values (`stat_smooth()`). ## Warning: Removed 2 rows containing missing values (`geom_point()`). print(g) Figure 7: Participant-level associations between HEP effect size and self-reported anxiety ratings. (A) Correlations with HEP effect size for both state (left) and trait (right) anxiety. (B) EEG grand averaged timeseries broken by a median split on state anxiety.\nWe can see that for state (but not trait) anxiety, there is a significant, positive correlation with HEP effect size (*Figure* 7). This suggests that, as people are feeling more anxious in the moment, their sensitivity to cardiac signals is more coupled with their momentary changes in subjective arousal. What it means As your subjective arousal increases, your brain becomes more sensitive to your heart signals\u0026mdash;but if you\u0026rsquo;re higher in anxiety, that boost in sensitivity is even stronger We found that the brain\u0026rsquo;s response to heartbeats changes depending on how energized you feel‚Äîand that this effect is different for people with higher anxiety. When people were in a more amped-up state (what we‚Äôre calling high subjective arousal), their brains showed a stronger reaction to heartbeats. And for folks with high anxiety, this pattern was amplified.\nSo what does that mean, practically?\nIt suggests that when your energy level shifts‚Äîeven just quietly, while you‚Äôre resting‚Äîyour brain is tuning in to your body in a different way. And if you‚Äôre someone who struggles with anxiety, your brain might be tuning in differently altogether.\nThis matters because a lot of anxiety happens at rest, when we‚Äôre left alone with our thoughts. The brain networks that light up during rest are also the ones tied to rumination, worry, and ‚Äúwhat if‚Äù spirals. Our results suggest that these moments of rest may not be as neutral as they seem: your brain is actively tracking how your body feels, and if you\u0026rsquo;re anxious, it might be tracking differently.\nIn the future, this kind of research could inform better mental health tools. Imagine a wearable that doesn‚Äôt just track your heart rate, but notices when your brain‚Äôs response to your body changes in a way that predicts anxiety. Or an app that could nudge you toward a calming activity right when your internal signals suggest you\u0026rsquo;re about to start spiraling.\nMore broadly, this work shows that our internal world‚Äîhow we feel inside‚Äîhas a real, measurable footprint in the brain. It reinforces the idea that emotions aren‚Äôt just things we talk about in therapy‚Äîthey‚Äôre deeply embedded in how our body and brain talk to each other. And that connection might be key to understanding not just anxiety, but how we can better support mental health in everyday life.\nBack to homepage.\nPang, J., Tang, X., Li, H., Hu, Q., Cui, H., Zhang, L., Li, W., Zhu, Z., Wang, J., \u0026amp; Li, C. (2019). Altered Interoceptive Processing in Generalized Anxiety Disorder‚ÄîA Heartbeat-Evoked Potential Research. Frontiers in Psychiatry, 10, 616. https://doi.org/10.3389/fpsyt.2019.00616\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nColl, M.-P., Hobson, H., Bird, G., \u0026amp; Murphy, J. (2021). Systematic review and meta-analysis of the relationship between the heartbeat-evoked potential and interoception. Neuroscience \u0026amp; Biobehavioral Reviews, 122, 190‚Äì200. https://doi.org/10.1016/j.neubiorev.2020.12.012\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFourcade, A., Klotzsche, F., Hofmann, S. M., Mariola, A., Nikulin, V. V., Villringer, A., \u0026amp; Gaebler, M. (2024). Linking brain‚Äìheart interactions to emotional arousal in immersive virtual reality. Psychophysiology, e14696. https://doi.org/10.1111/psyp.14696\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKucyi, A., Kam, J. W. Y., Andrews-Hanna, J. R., Christoff, K., \u0026amp; Whitfield-Gabrieli, S. (2023). Recent advances in the neuroscience of spontaneous and off-task thought: Implications for mental health. Nature Mental Health, 1(11), 827‚Äì840. https://doi.org/10.1038/s44220-023-00133-w\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPark, H.-D., \u0026amp; Blanke, O. (2019). Heartbeat-evoked cortical responses: Underlying mechanisms, functional roles, and methodological considerations. NeuroImage, 197, 502‚Äì511. https://doi.org/10.1016/j.neuroimage.2019.04.081\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n", 
    "url": "\/2025\/04\/24\/does-the-brain-cope-with-anxiety-by-numbing-out\/"
        },
    
    
    "\/post\/": {
        
        "title": "Posts",
            "tags": [],
    "content": "", 
    "url": "\/post\/"
        },
    
    
    "\/2015\/01\/01\/more-project-summaries-coming-soon\/": {
        
        "title": "More project summaries coming soon",
            "tags": [],
    "content": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n", 
    "url": "\/2015\/01\/01\/more-project-summaries-coming-soon\/"
        },
    
    
    "\/about\/": {
        
        "title": "About",
            "tags": [],
    "content": " Hey y'all, I'm Dave Hey ChatGPT: Take all of the data from our previous interactions and write an \"About me\" paragraph for my website that lets the good people of the Internet know what I'm about. Meet Dr. David Braun‚Äîa cognitive neuroscientist, data scientist, and experienced meditator with a knack for making complexity feel grounded. With 11+ years of research behind him, David‚Äôs worked at the intersection of spontaneous thought, cognitive control, decision making, and epidemiology, using tools like R, Python, EEG, and computational and predictive modeling to unpack the messiness of the human mind. Whether it‚Äôs through code, conversation, or contemplation, David‚Äôs all about meaningful work that helps people‚Äîand doing it from a quiet spot in the woods, if he can help it.\nValues include kindness, patience, thoughtfulness, humility, curiosity, balance, and simplicity.\n", 
    "url": "\/about\/"
        },
    
    
    "\/categories\/": {
        
        "title": "Categories",
            "tags": [],
    "content": "", 
    "url": "\/categories\/"
        },
    
    
    "\/publications\/": {
        
        "title": "Publications",
            "tags": [],
    "content": "Under review Braun, D., Shareef-Trudeau, L., Rao, S., Cheesebrough, C., Kam, J. W. Y., Kucyi, A. (Under review). State anxiety modulates the relationship between neural processing of heartbeats and spontaneous fluctuations in subjective arousal. Journal of Neuroscience. https://doi.org/10.1101/2025.03.26.645574 2024 McAndrew, T., Gibson, G. C., Braun, D., Srivastava, A, \u0026amp; Brown, K. (2024). Chimeric forecasting: An experiment to leverage human judgment to improve forecasts of infectious disease using simulated surveillance data. Epidemics, 47, 100756. https://doi.org/10.1016/j.epidem.2024.100756\nBounyarith, T., Braun, D., \u0026amp; Kucyi, A. (2024). Examining the neural bases of spontaneous mental experiences with real-time fMRI. Peer Community in Registered Reports [Stage 1 Registered Report: In- Principle Accepted]. https://osf.io/sd4hu\nKucyi, A., Anderson, N., Bounyarith, T., Braun, D., Shareef-Trudeau, L., Treves, I., \u0026hellip; \u0026amp; Hung, S. (2024). Individual variability in neural representations of mind wandering. Network Neuroscience, 8, 808-856. https://doi.org/10.1162/netn_a_00387.\nMcAndrew, T., Gibson, G. C., Braun, D., Srivastava, A. \u0026amp; Brown, K. (2024). Chimeric Forecasting: An experiment to leverage human judgment to improve forecasts of infectious disease using simulated surveillance data. Epidemics, 47, 100756. https://doi.org/10.1016/j.epidem.2024.100756.\nMittelstadt, V., Mackenzie, I. G., Braun, D., \u0026amp; Arrington, K. (2024). Reactive and proactive control processes in voluntary task choice. Memory and Cognition, 52, 419-429. https://doi.org/10.3758/s13421-023-01470-y\n2022 McAndrew, T., Codi, A., Cambeiro, J., Besiroglu, T., Braun, D., Chen, E., Enrique Urtubey de C√©saris, L., Luk, D. (2022). Chimeric forecasting: Combining probabilistic predictions from computational models and human judgment. BMC Infectious Diseases, 22, 1-17. https://doi.org/10.1186/s12879-022-07794-5.\nBraun, D., Ingram, D., Ingram, D., Khan, B., Marsh, J., \u0026amp; McAndrew, T. (2022). Crowdsourced perceptions and COVID-19: Improving computational forecasts of US national incident cases of COVID-19 with crowdsourced perceptions of human behavior. JMIR Public Health Surveill, 8, 1-18. http://dx.doi.org/10.2196/39336\nCodi, A., Luk, D., Braun, D., Cambeiro, J., Besiroglu, T. Chen, E., Enrique Urtubey de Cesaris, L., Bocchini, P., McAndrew, T. (2022). Aggregating human judgment probabilistic predictions of COVID-19 transmission, burden, and preventative measures. American Journal of Public Health. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9016644/\nMcAndrew, T., Majumder, M. S., Lover, A. A., Venkatramanan, S., Boccini, P., Besiroglu, T., Codi, A., **Braun, D.*, Dempsey, G., Abbott, S., Chevalier, S., Bosse, N. I., Cambeiro, J. (2022). Human judgment forecasts of human monkeypox transmission and burden in non-endemic countries. Lancet Digital Health. https://doi.org/10.1016/S2589-7500(22)00127-3\nEarlier Marvel, C. J., Bates, J. E., Hambric, C. E., Braun, D., Arrington, C. M., \u0026amp; Harmer, M. P. (2021). The Lehigh Presidential Nano-Human Interface Initiative: Covergence of materials and cognitive sciences. MRS Bulletin. https://doi.org/10.1557/s43577-021-00232-y\nBraun, D., Arrington, C. M. (2018). Assessing the role of effort and reward in task selection using a reward-based voluntary task switching paradigm. Psychological Research, 82, 54-64. https://doi.org/10.1007/s00426-017-0919-x\nFleck, J. I. \u0026amp; Braun, D. (2015). The impact of eye movements on a verbal creativity task. Journal of Cognitive Psychology, 27, 866-881. https://doi.org/10.1080/20445911.2015.1036057\n", 
    "url": "\/publications\/"
        },
    
    
    "\/tags\/": {
        
        "title": "Tags",
            "tags": [],
    "content": "", 
    "url": "\/tags\/"
        },
    
    }
</script>

<script src="/js/lunr.min.js"></script>
<script src="/js/search.js"></script>

</footer></body>
</html>
